{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['year', 'release_date', 'title', 'genre', 'international_box_office',\n",
      "       'domestic_box_office', 'worldwide_box_office', 'production_budget',\n",
      "       'Unnamed: 8', 'opening_weekend', 'theatre_count', 'avg run per theatre',\n",
      "       'runtime', 'keywords', 'creative_type', 'url'],\n",
      "      dtype='object')\n",
      "Number of non-null rows in 'title' column: 30612\n",
      "Total number of rows in the DataFrame: 30612\n",
      "                                      title  international_box_office  \\\n",
      "0                              bakha satang                   76576.0   \n",
      "1                                 antitrust                 6900000.0   \n",
      "2                                  santitos                       NaN   \n",
      "3                       frank mcklusky c i                        NaN   \n",
      "4                        a walk to remember                 4833792.0   \n",
      "...                                     ...                       ...   \n",
      "30607                jokbeoldu sinmun iyagi                   12356.0   \n",
      "30608                      my salinger year                  914119.0   \n",
      "30609                     escort vehicle 36                  240000.0   \n",
      "30610                               the dry                16987526.0   \n",
      "30611  posledniy bogatyr  koren         zla                33396899.0   \n",
      "\n",
      "       domestic_box_office  worldwide_box_office  \n",
      "0                      NaN               76576.0  \n",
      "1               10965209.0            17865209.0  \n",
      "2                 378562.0                   NaN  \n",
      "3                      NaN                   NaN  \n",
      "4               41227069.0            46060861.0  \n",
      "...                    ...                   ...  \n",
      "30607                  NaN               12356.0  \n",
      "30608              54730.0              968849.0  \n",
      "30609                  NaN              240000.0  \n",
      "30610             364397.0            17351923.0  \n",
      "30611                  NaN            33396899.0  \n",
      "\n",
      "[30612 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the Sales Data file\n",
    "df1 = pd.read_csv('C:\\\\Users\\\\pc\\\\Downloads\\\\Test\\\\salesData.csv',  encoding='ISO-8859-1') \n",
    "\n",
    "# View the columns to check if it works\n",
    "print(df1.columns)\n",
    "\n",
    "#drop all columns except title\n",
    "df1 = df1.drop(columns=['year', 'release_date', 'genre', 'production_budget',\n",
    "       'Unnamed: 8', 'opening_weekend', 'theatre_count', 'avg run per theatre',\n",
    "       'runtime', 'keywords', 'creative_type', 'url'])\n",
    "\n",
    "\n",
    "# Function to clean the title text\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):  # Check if the text is NaN\n",
    "        return ''  # Return an empty string or handle NaN as needed\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters using regex (keeping only alphanumeric characters and spaces)\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'title' column\n",
    "df1['title'] = df1['title'].apply(clean_text)\n",
    "\n",
    "df1.head()\n",
    "\n",
    "# Count non-null values in the 'title' column\n",
    "non_null_count = df1['title'].count()\n",
    "print(f\"Number of non-null rows in 'title' column: {non_null_count}\")\n",
    "# Count total rows in the DataFrame\n",
    "total_rows = df1.shape[0]\n",
    "print(f\"Total number of rows in the DataFrame: {total_rows}\")\n",
    "\n",
    "# search_title = '808'\n",
    "# result_df1 = df1.loc[df1['title'].str.contains(search_title, case=False, na=False)]\n",
    "\n",
    "print(df1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url', 'title', 'studio', 'rating', 'runtime', 'cast', 'director',\n",
      "       'genre', 'summary', 'awards', 'metascore', 'userscore', 'RelDate'],\n",
      "      dtype='object')\n",
      "Number of non-null rows in 'title' column: 11364\n",
      "Total number of rows in the DataFrame: 11364\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the metaClean43Brightspace.csv file\n",
    "df2 = pd.read_csv('C:\\\\Users\\\\pc\\\\Downloads\\\\Test\\\\metaClean43Brightspace.csv',  encoding='ISO-8859-1')  # If the delimiter is different, replace '\\t' with ',' or ' '\n",
    "\n",
    "# View the columns to check if it works\n",
    "print(df2.columns)\n",
    "\n",
    "#drop all columns and leave the title column\n",
    "df2 = df2.drop(columns=['url', 'studio', 'rating', 'runtime', 'cast', 'director',\n",
    "       'genre', 'summary', 'awards', 'metascore', 'userscore', 'RelDate'])\n",
    "\n",
    "\n",
    "\n",
    "# Function to clean the title text\n",
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters using regex (keeping only alphanumeric characters and spaces)\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'title' column\n",
    "df2['title'] = df2['title'].apply(clean_text)\n",
    "\n",
    "df2.head()\n",
    "\n",
    "# Count non-null values in the 'title' column\n",
    "non_null_count = df2['title'].count()\n",
    "print(f\"Number of non-null rows in 'title' column: {non_null_count}\")\n",
    "# Count total rows in the DataFrame\n",
    "total_rows = df2.shape[0]\n",
    "print(f\"Total number of rows in the DataFrame: {total_rows}\")\n",
    "\n",
    "# search_title = 'brother'\n",
    "# result_df2 = df2.loc[df['title'].str.contains(search_title, case=False, na=False)]\n",
    "\n",
    "\n",
    "# print(result_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url', 'idvscore', 'reviewer', 'dateP', 'Rev', 'WC', 'Analytic',\n",
      "       'Clout', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'Dic', 'function',\n",
      "       'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they', 'ipron',\n",
      "       'article', 'prep', 'auxverb', 'adverb', 'conj', 'negate', 'verb', 'adj',\n",
      "       'compare', 'interrog', 'number', 'quant', 'affect', 'posemo', 'negemo',\n",
      "       'anx', 'anger', 'sad', 'social', 'family', 'friend', 'female', 'male',\n",
      "       'cogproc', 'insight', 'cause', 'discrep', 'tentat', 'certain', 'differ',\n",
      "       'percept', 'see', 'hear', 'feel', 'bio', 'body', 'health', 'sexual',\n",
      "       'ingest', 'drives', 'affiliation', 'achieve', 'power', 'reward', 'risk',\n",
      "       'focuspast', 'focuspresent', 'focusfuture', 'relativ', 'motion',\n",
      "       'space', 'time', 'work', 'leisure', 'home', 'money', 'relig', 'death',\n",
      "       'informal', 'swear', 'netspeak', 'assent', 'nonflu', 'filler',\n",
      "       'AllPunc', 'Period', 'Comma', 'Colon', 'SemiC', 'QMark', 'Exclam',\n",
      "       'Dash', 'Quote', 'Apostro', 'Parenth', 'OtherP'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.metacritic.com/movie/bronson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.metacritic.com/movie/bronson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.metacritic.com/movie/bronson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.metacritic.com/movie/bronson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.metacritic.com/movie/bronson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        url\n",
       "0  https://www.metacritic.com/movie/bronson\n",
       "1  https://www.metacritic.com/movie/bronson\n",
       "2  https://www.metacritic.com/movie/bronson\n",
       "3  https://www.metacritic.com/movie/bronson\n",
       "4  https://www.metacritic.com/movie/bronson"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the ExpertReviewsClean43LIWC.csv file\n",
    "df3 = pd.read_csv('C:\\\\Users\\\\pc\\\\Downloads\\\\Test\\\\ExpertReviewsClean43LIWC.csv',  encoding='ISO-8859-1')  \n",
    "\n",
    "# View the columns to check if the file was read successfully \n",
    "print(df3.columns)\n",
    "\n",
    "#drop columns\n",
    "df3 = df3.drop(columns=['idvscore', 'reviewer', 'dateP', 'Rev', 'WC', 'Analytic',\n",
    "       'Clout', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'Dic', 'function',\n",
    "       'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they', 'ipron',\n",
    "       'article', 'prep', 'auxverb', 'adverb', 'conj', 'negate', 'verb', 'adj',\n",
    "       'compare', 'interrog', 'number', 'quant', 'affect', 'posemo', 'negemo',\n",
    "       'anx', 'anger', 'sad', 'social', 'family', 'friend', 'female', 'male',\n",
    "       'cogproc', 'insight', 'cause', 'discrep', 'tentat', 'certain', 'differ',\n",
    "       'percept', 'see', 'hear', 'feel', 'bio', 'body', 'health', 'sexual',\n",
    "       'ingest', 'drives', 'affiliation', 'achieve', 'power', 'reward', 'risk',\n",
    "       'focuspast', 'focuspresent', 'focusfuture', 'relativ', 'motion',\n",
    "       'space', 'time', 'work', 'leisure', 'home', 'money', 'relig', 'death',\n",
    "       'informal', 'swear', 'netspeak', 'assent', 'nonflu', 'filler',\n",
    "       'AllPunc', 'Period', 'Comma', 'Colon', 'SemiC', 'QMark', 'Exclam',\n",
    "       'Dash', 'Quote', 'Apostro', 'Parenth', 'OtherP'])\n",
    "\n",
    "df3.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_16176\\3941476314.py:2: DtypeWarning: Columns (1,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df4 = pd.read_csv('C:\\\\Users\\\\pc\\\\Downloads\\\\Test\\\\UserReviewsClean43LIWC.csv',  encoding='ISO-8859-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url', 'idvscore', 'reviewer', 'dateP', 'Rev', 'thumbsUp', 'thumbsTot',\n",
      "       'WC', 'Analytic', 'Clout', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'Dic',\n",
      "       'function', 'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they',\n",
      "       'ipron', 'article', 'prep', 'auxverb', 'adverb', 'conj', 'negate',\n",
      "       'verb', 'adj', 'compare', 'interrog', 'number', 'quant', 'affect',\n",
      "       'posemo', 'negemo', 'anx', 'anger', 'sad', 'social', 'family', 'friend',\n",
      "       'female', 'male', 'cogproc', 'insight', 'cause', 'discrep', 'tentat',\n",
      "       'certain', 'differ', 'percept', 'see', 'hear', 'feel', 'bio', 'body',\n",
      "       'health', 'sexual', 'ingest', 'drives', 'affiliation', 'achieve',\n",
      "       'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture',\n",
      "       'relativ', 'motion', 'space', 'time', 'work', 'leisure', 'home',\n",
      "       'money', 'relig', 'death', 'informal', 'swear', 'netspeak', 'assent',\n",
      "       'nonflu', 'filler', 'AllPunc', 'Period', 'Comma', 'Colon', 'SemiC',\n",
      "       'QMark', 'Exclam', 'Dash', 'Quote', 'Apostro', 'Parenth', 'OtherP'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.metacritic.com/movie/bronson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.metacritic.com/movie/bronson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.metacritic.com/movie/bronson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.metacritic.com/movie/bronson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.metacritic.com/movie/bronson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        url\n",
       "0  https://www.metacritic.com/movie/bronson\n",
       "1  https://www.metacritic.com/movie/bronson\n",
       "2  https://www.metacritic.com/movie/bronson\n",
       "3  https://www.metacritic.com/movie/bronson\n",
       "4  https://www.metacritic.com/movie/bronson"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the file with a different encoding (e.g., 'ISO-8859-1' or 'latin1')\n",
    "df4 = pd.read_csv('C:\\\\Users\\\\pc\\\\Downloads\\\\Test\\\\UserReviewsClean43LIWC.csv',  encoding='ISO-8859-1')  \n",
    "\n",
    "# View the columns to check if the file was read successfully \n",
    "\n",
    "print(df4.columns)\n",
    "\n",
    "#drop columns\n",
    "df4 = df4.drop(columns=['idvscore', 'reviewer', 'dateP', 'Rev', 'thumbsUp', 'thumbsTot',\n",
    "       'WC', 'Analytic', 'Clout', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'Dic',\n",
    "       'function', 'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they',\n",
    "       'ipron', 'article', 'prep', 'auxverb', 'adverb', 'conj', 'negate',\n",
    "       'verb', 'adj', 'compare', 'interrog', 'number', 'quant', 'affect',\n",
    "       'posemo', 'negemo', 'anx', 'anger', 'sad', 'social', 'family', 'friend',\n",
    "       'female', 'male', 'cogproc', 'insight', 'cause', 'discrep', 'tentat',\n",
    "       'certain', 'differ', 'percept', 'see', 'hear', 'feel', 'bio', 'body',\n",
    "       'health', 'sexual', 'ingest', 'drives', 'affiliation', 'achieve',\n",
    "       'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture',\n",
    "       'relativ', 'motion', 'space', 'time', 'work', 'leisure', 'home',\n",
    "       'money', 'relig', 'death', 'informal', 'swear', 'netspeak', 'assent',\n",
    "       'nonflu', 'filler', 'AllPunc', 'Period', 'Comma', 'Colon', 'SemiC',\n",
    "       'QMark', 'Exclam', 'Dash', 'Quote', 'Apostro', 'Parenth', 'OtherP'])\n",
    "\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-null rows in 'title' column: 319662\n",
      "Total number of rows in the DataFrame: 319662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                            bronson\n",
       "1                           disgrace\n",
       "2                    a screaming man\n",
       "3                     lovers of hate\n",
       "4    phil ochs there but for fortune\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the file with a different encoding (e.g., 'ISO-8859-1' or 'latin1')\n",
    "df41 = pd.read_csv('C:\\\\Users\\\\pc\\\\Downloads\\\\Test\\\\UserReviewsURL.csv',  encoding='ISO-8859-1')  \n",
    "df41.head()\n",
    "\n",
    "def extract_last_part(url):\n",
    "    path = urlparse(url).path\n",
    "    title = path.split('/')[-1]\n",
    "    return title\n",
    "\n",
    "# Apply the function to the 'URL' column to create a new 'title' column\n",
    "df41['title'] = df41['url'].apply(extract_last_part)\n",
    "\n",
    "# Function to clean the title text\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):  # Check if the text is NaN\n",
    "        return ''  # Return an empty string or handle NaN as needed\n",
    "     #Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters using regex (keeping only alphanumeric characters and spaces)\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Drop duplicates in the 'title' column to show each title just once\n",
    "userReviews_unique_titles = df41['title'].drop_duplicates().reset_index(drop=True).apply(clean_text)\n",
    "\n",
    "# Count non-null values in the 'title' column\n",
    "non_null_count = df41['title'].count()\n",
    "print(f\"Number of non-null rows in 'title' column: {non_null_count}\")\n",
    "\n",
    "# Count total rows in the DataFrame\n",
    "total_rows = df41.shape[0]\n",
    "print(f\"Total number of rows in the DataFrame: {total_rows}\")\n",
    "\n",
    "#print(unique_titles)\n",
    "userReviews_unique_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        TITLE     ID\n",
      "0                bakha satang      1\n",
      "1                   antitrust      2\n",
      "2                    santitos      3\n",
      "3          frank mcklusky c i      4\n",
      "4          a walk to remember      5\n",
      "...                       ...    ...\n",
      "34416         metropolis 2002  34417\n",
      "34417          lovely amazing  34418\n",
      "34418              siddhartha  34419\n",
      "34419  rocco and his brothers  34420\n",
      "34420       y tu mama tambien  34421\n",
      "\n",
      "[34421 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Paths to the CSV files\n",
    "allMovieTitlesDataFrames = [\n",
    "    'C:\\\\Users\\\\pc\\\\Downloads\\\\Test\\\\salesDataMovieTitles.csv',\n",
    "    'C:\\\\Users\\\\pc\\\\Downloads\\\\Test\\\\metaCleanMovieTitles.csv',\n",
    "    'C:\\\\Users\\\\pc\\\\Downloads\\\\Test\\\\expertReviewsUniqueMovieTitles.csv',\n",
    "    'C:\\\\Users\\\\pc\\\\Downloads\\\\Test\\\\userReviewsUniqueMovieTitles.csv'\n",
    "]\n",
    "\n",
    "# List to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Read each CSV file, rename the column to 'TITLE', and store them in the list\n",
    "for file_path in allMovieTitlesDataFrames:\n",
    "    df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "    df.columns = ['TITLE']  # Ensure the column is named 'TITLE'\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# 2. Strip any leading/trailing whitespace\n",
    "combined_df['TITLE'] = combined_df['TITLE'].str.lower().str.strip()\n",
    "\n",
    "# Remove duplicate rows based on the 'TITLE' column\n",
    "unique_df = combined_df.drop_duplicates(subset=['TITLE']).reset_index(drop=True)\n",
    "\n",
    "# Assign a unique ID to each row\n",
    "unique_df['ID'] = range(1, len(unique_df) + 1)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(unique_df)\n",
    "\n",
    "#print(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results found for '19 m':\n",
      "                                      TITLE     ID\n",
      "24426  andre rieus 2019 maastricht concert  24427\n",
      "25490                               19 mar  25491\n"
     ]
    }
   ],
   "source": [
    "def search_title(unique_df, search_term):\n",
    "    # Convert the 'TITLE' column to lowercase, replacing NaNs with an empty string\n",
    "    unique_df['TITLE'] = unique_df['TITLE'].fillna('').str.lower()\n",
    "    \n",
    "    # Convert the search term to lowercase\n",
    "    search_term = search_term.lower()\n",
    "    \n",
    "    # Filter the DataFrame to find rows where 'TITLE' contains the search term\n",
    "    result_df = unique_df[unique_df['TITLE'].str.contains(search_term)]\n",
    "    \n",
    "    # Check if the result is empty\n",
    "    if result_df.empty:\n",
    "        print(f\"No results found for '{search_term}'\")\n",
    "    else:\n",
    "        print(f\"Results found for '{search_term}':\\n\", result_df)\n",
    "\n",
    "# Example usage to search for a specific Movie_title\n",
    "search_term ='19 m'  # You can replace 'Bronson' with the title you're looking for\n",
    "search_title(unique_df, search_term)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the above code gets all the movie titles from all four tables and removes duplicates so that the Movie_ID can be assigned to every movie. Lastly, a search function was created to test the Table to and make sure no duplicates are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Movie_ID', 'worldwide_box_office'], dtype='object')\n",
      "Index(['TITLE', 'Movie_ID'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read the Sales Data file\n",
    "df_BoxOffice = pd.read_csv('C:\\\\Users\\\\pc\\\\Downloads\\\\Test\\\\BoxOfficeWithUniqueID.csv',  encoding='ISO-8859-1') \n",
    "df_MovieIDTable = pd.read_csv('allMoviesWithUniqueID.csv', sep=None, engine='python', encoding='ISO-8859-1')\n",
    "df_MovieIDTable = df_MovieIDTable.rename(columns={\"ID\": \"Movie_ID\"})\n",
    "print(df_BoxOffice.columns)\n",
    "print(df_MovieIDTable.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>worldwide_box_office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bakha satang</td>\n",
       "      <td>1</td>\n",
       "      <td>76576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antitrust</td>\n",
       "      <td>2</td>\n",
       "      <td>17865209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>santitos</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frank mcklusky c i</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a walk to remember</td>\n",
       "      <td>5</td>\n",
       "      <td>46060861.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TITLE  Movie_ID  worldwide_box_office\n",
       "0        bakha satang         1               76576.0\n",
       "1           antitrust         2            17865209.0\n",
       "2            santitos         3                   NaN\n",
       "3  frank mcklusky c i         4                   NaN\n",
       "4  a walk to remember         5            46060861.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes on 'Movie_ID' column\n",
    "df_NewMovieTable = pd.merge(df_MovieIDTable, df_BoxOffice[['Movie_ID', 'worldwide_box_office']], on='Movie_ID', how='left')\n",
    "\n",
    "# Display the merged dataframe\n",
    "df_NewMovieTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import psycopg2\n",
    "\n",
    "try:\n",
    "    # Connect to the PostgreSQL database\n",
    "    conn = psycopg2.connect(\n",
    "        dbname='DMGroupAssignment',\n",
    "        user='postgres',\n",
    "        password='Okpanachi',\n",
    "        host='localhost',\n",
    "        port='5432'\n",
    "    )\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create the Movie table\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS MovieTable (\n",
    "        Movie_ID INTEGER PRIMARY KEY,\n",
    "        TITLE VARCHAR(255),\n",
    "        worldwide_box_office DECIMAL(15, 2)\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit()\n",
    "\n",
    "    # Insert data into the MovieTable\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO MovieTable (Movie_ID, TITLE, worldwide_box_office)\n",
    "    VALUES (%s, %s, %s)\n",
    "    ON CONFLICT (Movie_ID) DO UPDATE\n",
    "    SET TITLE = EXCLUDED.TITLE,\n",
    "        worldwide_box_office = EXCLUDED.worldwide_box_office;\n",
    "    \"\"\"\n",
    "\n",
    "    # Loop through the DataFrame and execute the insert query for each row\n",
    "    for index, row in df_NewMovieTable.iterrows():\n",
    "        cursor.execute(insert_query, (row['Movie_ID'], row['TITLE'], row['worldwide_box_office']))\n",
    "\n",
    "    # Commit the transaction to save changes to the database\n",
    "    conn.commit()\n",
    "    \n",
    "\n",
    "except Exception as error:\n",
    "    print(f\"Error: {error}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the cursor and connection are closed\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if conn:\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'international_box_office', 'domestic_box_office',\n",
      "       'worldwide_box_office', 'production_budget', 'normalized_title',\n",
      "       'Movie_ID'],\n",
      "      dtype='object')\n",
      "   Movie_ID  production_budget\n",
      "0         1                NaN\n",
      "1         2         30000000.0\n",
      "2         3                NaN\n",
      "3         4                NaN\n",
      "4         5         11000000.0\n"
     ]
    }
   ],
   "source": [
    "# Read the Sales Data file\n",
    "df_SalesInfo = pd.read_csv('C:\\\\Users\\\\pc\\\\Downloads\\\\Test\\\\salesData.csv',  encoding='ISO-8859-1') \n",
    "df_MovieTable = pd.read_csv('allMoviesWithUniqueID.csv', sep=None, engine='python', encoding='ISO-8859-1')\n",
    "df_MovieTable = df_MovieTable.rename(columns={\"ID\": \"Movie_ID\"})\n",
    "\n",
    "# View the columns to check if it works\n",
    "#print(df1.columns)\n",
    "\n",
    "#drop all columns except title\n",
    "df_SalesInfo = df_SalesInfo.drop(columns=['year', 'release_date', 'genre',\n",
    "       'Unnamed: 8', 'opening_weekend', 'theatre_count', 'avg run per theatre',\n",
    "       'runtime', 'keywords', 'creative_type', 'url'])\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):  # Check if the text is NaN\n",
    "        return ''  # Return an empty string or handle NaN as needed\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "# Apply the cleaning function to the 'title' column\n",
    "df_SalesInfo['title'] = df_SalesInfo['title'].apply(clean_text)\n",
    "\n",
    "df_SalesInfo['normalized_title'] = df_SalesInfo['title'].apply(clean_text)\n",
    "df_MovieTable['normalized_title'] = df_MovieTable['TITLE'].apply(clean_text)\n",
    "\n",
    "df_SalesInfo = df_SalesInfo.merge(df_MovieTable[['normalized_title', 'Movie_ID']], \n",
    "                                             on='normalized_title', how='left')\n",
    "\n",
    "\n",
    "df_SalesInfo = df_SalesInfo.drop_duplicates()\n",
    "\n",
    "print(df_SalesInfo.columns)\n",
    "\n",
    "df_BudgetTable = df_SalesInfo[['Movie_ID', 'production_budget']]\n",
    "print(df_BudgetTable.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched rows in df_SalesInfo:\n",
      "Empty DataFrame\n",
      "Columns: [title, normalized_title]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "unmatched_Sales = df_SalesInfo[df_SalesInfo['Movie_ID'].isna()]\n",
    "\n",
    "print(\"Unmatched rows in df_SalesInfo:\")\n",
    "print(unmatched_Sales[['title', 'normalized_title']])\n",
    "\n",
    "#merged_df.to_csv('merged.csv', index=False, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Movie_ID  production_budget\n",
      "0         1                NaN\n",
      "1         2         30000000.0\n",
      "2         3                NaN\n",
      "3         4                NaN\n",
      "4         5         11000000.0\n"
     ]
    }
   ],
   "source": [
    "df_BudgetTable = df_SalesInfo[['Movie_ID', 'production_budget']]\n",
    "print(df_BudgetTable.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Connect to the PostgreSQL database\n",
    "    conn = psycopg2.connect(\n",
    "        dbname='DMGroupAssignment',\n",
    "        user='postgres',\n",
    "        password='Okpanachi',\n",
    "        host='localhost',\n",
    "        port='5432'\n",
    "    )\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create the ProductionBudget table with an additional 'title' column\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS ProductionBudget (\n",
    "        Movie_ID INTEGER PRIMARY KEY,\n",
    "        production_budget DECIMAL(15, 2)\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit()\n",
    "\n",
    "    # Insert data into the ProductionBudget table with an upsert mechanism\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO ProductionBudget (Movie_ID, production_budget)\n",
    "    VALUES (%s, %s)\n",
    "    ON CONFLICT (Movie_ID) DO UPDATE\n",
    "    SET production_budget = EXCLUDED.production_budget;\n",
    "    \"\"\"\n",
    "\n",
    "    # Loop through the DataFrame and execute the insert query for each row\n",
    "    for index, row in df_BudgetTable.iterrows():\n",
    "        cursor.execute(insert_query, (row['Movie_ID'], row['production_budget']))\n",
    "\n",
    "    # Commit the transaction to save changes to the database\n",
    "    conn.commit()\n",
    "\n",
    "except Exception as error:\n",
    "    print(f\"Error: {error}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the cursor and connection are closed\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                title              genre genre_id\n",
      "0        bakha satang              Drama       06\n",
      "1           antitrust  Thriller/Suspense       13\n",
      "2            santitos                NaN      NaN\n",
      "3  frank mcklusky c i                NaN      NaN\n",
      "4  a walk to remember              Drama       06\n"
     ]
    }
   ],
   "source": [
    "# Read the Sales Data file\n",
    "df_SalesData = pd.read_csv('salesData.csv',  encoding='ISO-8859-1') \n",
    "df_NMovieTable = pd.read_csv('NewMovieTable.csv', sep=None, engine='python', encoding='ISO-8859-1')\n",
    "\n",
    "# View the columns to check if it works\n",
    "#print(df1.columns)\n",
    "\n",
    "# Drop unnecessary columns from SalesData\n",
    "df_SalesData = df_SalesData.drop(columns=['year', 'international_box_office', 'domestic_box_office', 'worldwide_box_office', 'release_date', 'Unnamed: 8', 'opening_weekend', 'theatre_count', 'avg run per theatre',\n",
    "       'runtime', 'production_budget', 'keywords', 'creative_type', 'url'])\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):  # Check if the text is NaN\n",
    "        return ''  # Return an empty string or handle NaN as needed\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "# Apply the cleaning function to the 'title' column\n",
    "df_SalesData['title'] = df_SalesData['title'].apply(clean_text)\n",
    "\n",
    "df_SalesData['normalized_title'] = df_SalesData['title'].apply(clean_text)\n",
    "df_NMovieTable['normalized_title'] = df_NMovieTable['TITLE'].apply(clean_text)\n",
    "\n",
    "df_SalesData = df_SalesData.merge(df_NMovieTable[['normalized_title', 'Movie_ID']], \n",
    "                                             on='normalized_title', how='left')\n",
    "\n",
    "\n",
    "df_SalesData = df_SalesData.drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "# Handle NaN values in the 'genre' column by excluding them from the ID assignment\n",
    "# We'll only assign IDs to rows where 'genre' is not NaN\n",
    "df_SalesData['genre_id'] = (\n",
    "    df_SalesData['genre']\n",
    "    .where(df_SalesData['genre'].notna())  # Keep NaN as NaN\n",
    "    .groupby(df_SalesData['genre'])\n",
    "    .ngroup()  # Assign unique integers to each genre group starting from 0\n",
    "    .astype('Int64')  # Ensures that NaN is retained and non-NaN values are integers\n",
    ")\n",
    "\n",
    "# Convert non-NaN values to string and pad with leading zeros, leave NaN as it is\n",
    "df_SalesData['genre_id'] = (\n",
    "    df_SalesData['genre_id']\n",
    "    .apply(lambda x: str(int(x)).zfill(2) if pd.notna(x) else x)  # Format with leading zeros, no prefix\n",
    ")\n",
    "\n",
    "# Print the columns and the final DataFrame\n",
    "print(df_SalesData[['title', 'genre', 'genre_id']].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched rows in df_SalesData:\n",
      "Empty DataFrame\n",
      "Columns: [title, normalized_title]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "Genre_Sales = df_SalesData[df_SalesData['Movie_ID'].isna()]\n",
    "\n",
    "print(\"Unmatched rows in df_SalesData:\")\n",
    "print(Genre_Sales[['title', 'normalized_title']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Movie_ID genre_id              genre\n",
      "0         1       06              Drama\n",
      "1         2       13  Thriller/Suspense\n",
      "2         3      NaN                NaN\n",
      "3         4      NaN                NaN\n",
      "4         5       06              Drama\n"
     ]
    }
   ],
   "source": [
    "df_Genre_Sales = df_SalesData[['Movie_ID', 'genre_id', 'genre']]\n",
    "print(df_Genre_Sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    dbname='DMGroupAssignment',\n",
    "    user='postgres',\n",
    "    password='Okpanachi',\n",
    "    host='localhost',\n",
    "    port='5432'\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Update the table creation query with BIGINT for genre_ID and Movie_ID\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Genre (\n",
    "    genre_ID TEXT,\n",
    "    genre TEXT NOT NULL,\n",
    "    Movie_ID BIGINT PRIMARY KEY\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute the table creation query\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# Format genre_id with a leading zero\n",
    "df_Genre_Sales.loc[:, 'genre_id'] = df_Genre_Sales['genre_id'].apply(\n",
    "    lambda x: f\"{int(x):02}\" if pd.notna(x) else x\n",
    ")\n",
    "\n",
    "# Define the insert query with conflict handling on Movie_ID\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO Genre (genre_ID, genre, Movie_ID)\n",
    "VALUES (%s, %s, %s)\n",
    "ON CONFLICT (Movie_ID) DO UPDATE\n",
    "SET genre = EXCLUDED.genre,\n",
    "    genre_ID = EXCLUDED.genre_ID;\n",
    "\"\"\"\n",
    "\n",
    "# Insert data into the table\n",
    "for index, row in df_Genre_Sales.iterrows():\n",
    "    try:\n",
    "        cursor.execute(insert_query, (row['genre_id'], row['genre'], row['Movie_ID']))\n",
    "    except psycopg2.IntegrityError as e:\n",
    "        print(f\"Error inserting row {index}: {e}\")\n",
    "        conn.rollback()  # Rollback on error\n",
    "    except psycopg2.DataError as e:\n",
    "        print(f\"Data error inserting row {index}: {e}\")\n",
    "        conn.rollback()  # Rollback on error\n",
    "    else:\n",
    "        conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
